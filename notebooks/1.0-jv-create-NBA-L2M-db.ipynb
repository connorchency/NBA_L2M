{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import urllib\n",
    "import PyPDF2\n",
    "import sqlite3\n",
    "import pdfquery\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_db(db_path):\n",
    "    \"\"\"Creates NBA-L2M.db and initial tables\"\"\"\n",
    "    conn = sqlite3.connect(os.path.join(db_path, \"NBA-L2M.db\"))\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS reports\n",
    "    (report PRIMARY KEY, away, away_score, home, home_score, \n",
    "    away_W, date, link, season);\"\"\")\n",
    "    \n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS calls\n",
    "    (report, period, time, call, committing, disadvantaged, \n",
    "    committing_team, disadvantaged_team, decision);\"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "def l2m_pdf_name(link):\n",
    "    \"\"\"Returns standardized pdf_name from link.\n",
    "    link - pdf url from NBA L2M archive\"\"\"\n",
    "    pdf_name = os.path.basename(link)\n",
    "    pdf_name = pdf_name.replace('@', '-')\n",
    "    pdf_name = pdf_name.replace('2017', '17')\n",
    "    pdf_name = pdf_name.replace('2016', '16')\n",
    "    pdf_name = pdf_name.replace('-1.pdf', '.pdf')\n",
    "    pdf_name = pdf_name.replace('-2.pdf', '.pdf')\n",
    "    pdf_name = pdf_name.replace('-4.pdf', '.pdf')\n",
    "    pdf_name = pdf_name.replace('b.pdf', '.pdf')\n",
    "    return pdf_name\n",
    "\n",
    "def get_l2m_links(url):\n",
    "    \"\"\"Returns a list of urls for all L2Ms.\n",
    "    url - path to NBA L2M archive\"\"\"\n",
    "    soup = BeautifulSoup(urllib.urlopen(url).read(), \"html.parser\")\n",
    "    l2ms =[]\n",
    "    for tag in soup.find_all(\"p\"):\n",
    "        link = tag.find(\"a\")\n",
    "        if link and link[\"href\"].endswith(\".pdf\"):\n",
    "            for l2m in tag.find_all(\"a\"):\n",
    "                l2ms.append([l2m[\"href\"], l2m_pdf_name(l2m[\"href\"])])\n",
    "    \n",
    "    # Filtering poorly named files (42/1008), mostly from 2015.\n",
    "    regex = re.compile(r\"^L2M-...-...-.*-...pdf$\")\n",
    "    l2ms = filter(lambda x: regex.search(x[1]), l2ms) \n",
    "    return l2ms\n",
    "\n",
    "def split_pdf_pages(pdf_path):\n",
    "    \"\"\"Split all pdfs by page.\n",
    "    pdf_path - full path of downloaded pdf\"\"\"\n",
    "    opened_pdf = PyPDF2.PdfFileReader(pdf_path, strict=False)\n",
    "    for i in range(opened_pdf.numPages):\n",
    "        output = PyPDF2.PdfFileWriter()\n",
    "        output.addPage(opened_pdf.getPage(i))\n",
    "        with open(os.path.join(pdf_path[:-24], \"{}-\".format(i) + pdf_path[10:]), \"wb\") as output_pdf:\n",
    "            output.write(output_pdf)\n",
    "    os.remove(pdf_path)\n",
    "            \n",
    "def scrape_l2m(pdf_path):\n",
    "    \"\"\"Scrape L2M data from each page.\n",
    "    pdf_path - full path of downloaded pdf\"\"\"\n",
    "    pdfs = os.listdir(pdf_path)\n",
    "    calls = []\n",
    "    for f in pdfs:\n",
    "        pdf = pdfquery.PDFQuery(os.path.join(pdf_path, f))\n",
    "        pdf.load()\n",
    "        rows = pdf.pq(\"\"\"LTTextLineHorizontal:contains(\"Video \")\"\"\")\n",
    "        for row in rows[2:]:\n",
    "            for i in row:\n",
    "                y0 = float(filter(lambda x: x[0] == \"y0\", i.items())[0][1])\n",
    "                peri = pdf.pq(\"LTTextLineHorizontal:in_bbox('0, {}, 90, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                time = pdf.pq(\"LTTextLineHorizontal:in_bbox('60, {}, 130, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                call = pdf.pq(\"LTTextLineHorizontal:in_bbox('100, {}, 260, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                comm = pdf.pq(\"LTTextLineHorizontal:in_bbox('200, {}, 400, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                disa = pdf.pq(\"LTTextLineHorizontal:in_bbox('360, {}, 500, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                deci = pdf.pq(\"LTTextLineHorizontal:in_bbox('500, {}, 560, {}')\".format(\n",
    "                        math.floor(y0 - 11), math.ceil(y0 + 14))).text()\n",
    "                calls.append([pdfs[0][-24:-4], peri, time, call, comm, disa, \"Nan\", \"Nan\", deci])\n",
    "    WL = re.findall('\\d+', pdf.pq(\"\"\"LTTextLineHorizontal:contains(\", 20{}\")\"\"\".format(f[-6:-4])).text())\n",
    "\n",
    "    report = [pdfs[0][-24:-4], pdfs[0][-20:-17], WL[0], pdfs[0][-16:-13], \n",
    "              WL[1], WL[0] > WL[1], pdfs[0][-12:-4]]\n",
    "    return calls, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## EXPECTED RUNTIME OF 70 MINUTES.\n",
    "pdf_path = \"../data/temp/\"\n",
    "db_path = \"../data/db/\"\n",
    "\n",
    "# Create db and tables (if necessary) and open connection to db.\n",
    "create_db(db_path)\n",
    "conn = sqlite3.connect(os.path.join(db_path, \"NBA-L2M.db\"))\n",
    "c = conn.cursor()\n",
    "\n",
    "# Get all L2M pdf links from nba.com archive.\n",
    "links = get_l2m_links(\"http://official.nba.com/nba-last-two-minute-reports-archive/\")\n",
    "n = len(links)\n",
    "times = []\n",
    "\n",
    "for idx, (link, pdf_name) in enumerate(links[:10]):\n",
    "    os.system(\"rm \" + pdf_path + \"*\") # Clear temp folder.\n",
    "    pdf = os.path.join(pdf_path, pdf_name) # Define local pdf path.\n",
    "    \n",
    "    urllib.urlretrieve(link, pdf) # Download L2M.\n",
    "    split_pdf_pages(pdf) # Split pdf into seperate pages.\n",
    "    calls, report = scrape_l2m(pdf_path) # Scrape all pages.\n",
    "    report.extend([link, 'Nan']) # Add link & 'season' filler to data.\n",
    "    \n",
    "    c.execute(\"\"\"\n",
    "    INSERT OR IGNORE INTO reports\n",
    "    VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\", report)\n",
    "    \n",
    "    c.executemany(\"\"\"\n",
    "    INSERT OR IGNORE INTO calls\n",
    "    VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\", calls)\n",
    "    \n",
    "    print \"\\r{3} {0:.2f}% Complete, ({1}/{2})\".format((float(idx + 1) / n) * 100, idx, n, pdf),\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# To Do:\n",
    "        \n",
    "1. Add player data to db (a table for each year in the db; https://www.basketball-reference.com/leagues/NBA_2017_totals.html).\n",
    "2. Add player's team to calls table.\n",
    "2. Add regular season/playoffs to reports table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
